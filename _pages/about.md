---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
# üòÑ Short Bio
I am currently pursuing my Ph.D. in the School of Automotive
Studies at Tongji University. I am co-supervised by Prof. Zhu Xichan and Prof. BAI JIE. Before joining TJU, I received my Bachelor‚Äôs Degree in School of Automotive Studies, Harbin Institute of Technology.

My research interests include 3D Object Detection, Occupancy Prediction, 4D Radar Perception, Multimodal Fusion, and Data Closed-Loop. My recent research focuses on End-to-End autonomous driving and Vision-Language-Action (VLA) models. I am currently actively seeking job opportunities and research collaborations.   <a href='https://scholar.google.cz/citations?user=gZfyMFwAAAAJ'><img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fzhenglianqing%2Fzhenglianqing.github.io%2Fgoogle-scholar-stats%2Fgs_data_shieldsio.json&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>

# üìñ Educations
- *2019.09 - present*, Ph.D. candidate in the School of Automotive
Studies, Tongji University, Shanghai. 
- *2015.09 - 2019.07*, B.E. in the School of Automotive
Studies, Harbin Institute of Technology, Weihai.
 
# üíª Internships
- 2024.03 - present,  Algorithm & Data intern, <a href='https://www.molardata.com/'>MOLAR INTELLIGENCE</a>, Hangzhou.
- 2023.07 - 2023.12,  Multimodal fusion intern, <a href='https://www.nio.cn/'>NIO</a>, Shanghai.
- 2020.09 - 2020.12,  Vision algorithm intern, <a href='https://www.hongjingdrive.com/'>HYPERVIEW</a>, Shanghai.

<!-- # üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üìù Publications
- **<u>Lianqing Zheng</u>**, Long Yang\*, Qunshu Lin\*, Wenjin Ai, Minghao Liu, Shouyi Lu, Jianan Liu et al. "OmniHD-Scenes: A Next-Generation Multimodal
Dataset for Autonomous Driving," *IEEE Transactions on Pattern Analysis and Machine Intelligence*, 2026.  [[Paper]](https://arxiv.org/abs/2412.10734) [[Project]](https://www.2077ai.com/OmniHD-Scenes/) [![](https://img.shields.io/github/stars/TJRadarLab/OmniHD-Scenes?style=social&label=Code+Stars)](https://github.com/TJRadarLab/OmniHD-Scenes) <a href='https://scholar.google.cz/citations?user=gZfyMFwAAAAJ'><img src="https://img.shields.io/badge/dynamic/json?url=https://raw.githubusercontent.com/zhenglianqing/zhenglianqing.github.io/google-scholar-stats/gs_data.json&query=$.publications.gZfyMFwAAAAJ:_FxGoFyzp5QC.num_citations&logo=Google%20Scholar&label=citations&color=9cf&labelColor=f6f6f6&style=flat"></a>
- **<u>Lianqing Zheng</u>**, Jianan Liu\*, Runwei Guan et al. "Doracamom: Joint 3D Detection and Occupancy Prediction with Multi-view 4D Radars and Cameras for Omnidirectional Perception," *IEEE Transactions on Circuits and Systems for Video Technology*, doi: 10.1109/TCSVT.2026.3657111.  [[Paper]](https://ieeexplore.ieee.org/abstract/document/11361108)[![](https://img.shields.io/github/stars/TJRadarLab/Doracamom?style=social&label=Code+Stars)](https://github.com/TJRadarLab/Doracamom) <a href='https://scholar.google.cz/citations?user=gZfyMFwAAAAJ'><img src="https://img.shields.io/badge/dynamic/json?url=https://raw.githubusercontent.com/zhenglianqing/zhenglianqing.github.io/google-scholar-stats/gs_data.json&query=$.publications.gZfyMFwAAAAJ:LkGwnXOMwfcC.num_citations&logo=Google%20Scholar&label=citations&color=9cf&labelColor=f6f6f6&style=flat"></a>
- **<u>Lianqing Zheng</u>**, Sen Li et al., "RCFusion: Fusing 4-D Radar and Camera With Bird‚Äôs-Eye View Features for 3-D Object Detection," *IEEE Transactions on Instrumentation and Measurement*, vol. 72, pp. 1-14, 2023. [[Paper]](https://ieeexplore.ieee.org/abstract/document/10138035) <a href='https://scholar.google.cz/citations?user=gZfyMFwAAAAJ'><img src="https://img.shields.io/badge/dynamic/json?url=https://raw.githubusercontent.com/zhenglianqing/zhenglianqing.github.io/google-scholar-stats/gs_data.json&query=$.publications.gZfyMFwAAAAJ:IjCSPb-OGe4C.num_citations&logo=Google%20Scholar&label=citations&color=9cf&labelColor=f6f6f6&style=flat"></a>
- **<u>Lianqing Zheng</u>**, Zhixiong Ma et al., "TJ4DRadSet: A 4D Radar Dataset for Autonomous Driving," 2022 IEEE 25th International Conference on Intelligent Transportation Systems (ITSC), Macau, China, 2022. [[Paper]](https://ieeexplore.ieee.org/abstract/document/9922539) [![](https://img.shields.io/github/stars/TJRadarLab/TJ4DRadSet?style=social&label=Code+Stars)](https://github.com/TJRadarLab/TJ4DRadSet) <a href='https://scholar.google.cz/citations?user=gZfyMFwAAAAJ'><img src="https://img.shields.io/badge/dynamic/json?url=https://raw.githubusercontent.com/zhenglianqing/zhenglianqing.github.io/google-scholar-stats/gs_data.json&query=$.publications.gZfyMFwAAAAJ:d1gkVwhDpl0C.num_citations&logo=Google%20Scholar&label=citations&color=9cf&labelColor=f6f6f6&style=flat"></a>
- Long Yang, **<u>Lianqing Zheng*</u>**, Wenjin Ai, Minghao Liu, Sen Li et al. "MetaOcc: Surround-View 4D Radar and Camera Fusion Framework for 3D Occupancy Prediction with Dual Training Strategies," arXiv preprint arXiv:2501.15384 (2025). (submitted to *IEEE T-ITS*)[[Paper]](https://arxiv.org/abs/2501.15384)[![](https://img.shields.io/github/stars/LucasYang567/MetaOcc?style=social&label=Code+Stars)](https://github.com/LucasYang567/MetaOcc) <a href='https://scholar.google.cz/citations?user=gZfyMFwAAAAJ'><img src="https://img.shields.io/badge/dynamic/json?url=https://raw.githubusercontent.com/zhenglianqing/zhenglianqing.github.io/google-scholar-stats/gs_data.json&query=$.publications.gZfyMFwAAAAJ:roLk4NBRz8UC.num_citations&logo=Google%20Scholar&label=citations&color=9cf&labelColor=f6f6f6&style=flat"></a>
- Xiaokai Bai, **<u>Lianqing Zheng</u>** et al. ‚ÄúSIFormer: Scene-Instance Aware Transformer for 3D Object Detection with 4D Radar and Camera‚Äù, *IEEE Transactions on Multimedia*, 2025.
- Zhiqiang Wei, **<u>Lianqing Zheng</u>**, Jianan Liu et al. "MS-Occ: Multi-Stage LiDAR-Camera Fusion for 3D Semantic Occupancy Prediction," *IEEE Robotics and Automation Letters*, vol. 11, no. 1, pp. 370-377, Jan. 2026, doi: 10.1109/LRA.2025.3632759.[[Paper]](https://ieeexplore.ieee.org/document/11247862) <a href='https://scholar.google.cz/citations?user=gZfyMFwAAAAJ'><img src="https://img.shields.io/badge/dynamic/json?url=https://raw.githubusercontent.com/zhenglianqing/zhenglianqing.github.io/google-scholar-stats/gs_data.json&query=$.publications.gZfyMFwAAAAJ:hqOjcs7Dif8C.num_citations&logo=Google%20Scholar&label=citations&color=9cf&labelColor=f6f6f6&style=flat"></a>
- Sihan Chen, **<u>Lianqing Zheng</u>** et al., "UMT-Net: A Uniform Multi-Task Network With Adaptive Task Weighting," *IEEE Transactions on Intelligent Vehicles*, vol. 9, no. 1, pp. 2304-2317, 2024. [[Paper]](https://ieeexplore.ieee.org/abstract/document/10264163) <a href='https://scholar.google.cz/citations?user=gZfyMFwAAAAJ'><img src="https://img.shields.io/badge/dynamic/json?url=https://raw.githubusercontent.com/zhenglianqing/zhenglianqing.github.io/google-scholar-stats/gs_data.json&query=$.publications.gZfyMFwAAAAJ:YsMSGLbcyi4C.num_citations&logo=Google%20Scholar&label=citations&color=9cf&labelColor=f6f6f6&style=flat"></a>
- Xiaokai Bai, Zhu Yu, **<u>Lianqing Zheng</u>** et al., "SGDet3D: Semantics and Geometry Fusion for 3D Object Detection Using 4D Radar and Camera," *IEEE Robotics and Automation Letters*, vol. 10, no. 1, pp. 828-835, 2025. [[Paper]](https://ieeexplore.ieee.org/abstract/document/10783046) [![](https://img.shields.io/github/stars/shawnnnkb/SGDet3D?style=social&label=Code+Stars)](https://github.com/shawnnnkb/SGDet3D) <a href='https://scholar.google.cz/citations?user=gZfyMFwAAAAJ'><img src="https://img.shields.io/badge/dynamic/json?url=https://raw.githubusercontent.com/zhenglianqing/zhenglianqing.github.io/google-scholar-stats/gs_data.json&query=$.publications.gZfyMFwAAAAJ:ufrVoPGSRksC.num_citations&logo=Google%20Scholar&label=citations&color=9cf&labelColor=f6f6f6&style=flat"></a>


  


# üéñ Honors and Awards
- 2023-2024 Weichai Doctoral Scholarship (top 5%, Ôø•20,000) [[IMG]](../honors_img/WEICHAI.jpg)
- 2021-2022 Outstanding Doctoral Freshman Scholarship (top 20%, Ôø•5,000) [[IMG]](../honors_img/Outstanding_Doctoral_Freshman_Scholarship.jpg)
- 2020-2021 Hydra-vision Scholarship (top 10%, Ôø•10,000) [[IMG]](../honors_img/XIONGTAO.jpg)
- 2020 Second Prize in the 17th "Huawei Cup" Chinese Postgraduate Mathematical Contest in Modeling [[IMG]](../honors_img/MCM.jpg)
- 2019 Outstanding Graduate of Shandong Province (top 5%) [[IMG]](../honors_img/Outstanding_Graduate_of_Shandong_Province.jpg)
- 2017-2018 China National Scholarship (top 1%, Ôø•8,000) [[IMG]](../honors_img/National_Scholarship.jpg)
- 2016-2017 First-Class Academic Scholarship (top 5%, Ôø•1,500) [[IMG]](../honors_img/renmin.jpg)

# üåüActivities
- 2025.03 Presenting the construction of the OmniHD-Scenes dataset at "Autonomous Driving Heart". [[Link]](https://mp.weixin.qq.com/s/kBSH3eYEI4D_93PYaxjjtA)
- 2025.01 Online technical sharing and exchange session with the TUM/MAN truck team. [[IMG1]](../images/felix.png) [[IMG2]](../images/fabian.png) [[IMG3]](../images/me.png)
- 2024.09 Attending the AEIF 2024 conference. [[IMG]](../images/AEIF.jpg)
- 2022.10 Delivered a presentation at ITSC 2022. [[IMG]](../images/ITSC.jpg)

# ‚úÖ Services
*Reviewer of AAAI, IEEE ICRA, IEEE ITSC*

*Reviewer of IEEE T-ITS, IEEE T-IV, IEEE RA-L, IEEE SENSORS Journal, IET RSN*

<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=-EBfrhoJmR4Y5DO37dfJ6ai50WCrptK2rhIvRrs2FSY&cl=ffffff&w=a"></script>

